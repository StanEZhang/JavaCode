# java面试逐字稿

## 一、自我介绍

- 【概括经历】：简单概括之前的经历
- 【匹配优势】：从过去工作中找到和应聘岗位匹配的优势
- 【说明选择】：说明为什么要选这个岗位、公司和行业

你好，我是小明，我有三份工作经历，都是在房地产公司做销售的。在销售工作中，会涉及到一些市场拓展、用户沟通、促成交易，以及配合一些线上线下的营销活动。

我之前的工作中有涉及到市场拓展，所以我对房地产行业的头部公司、行业发展以及政策都非常了解，我也会一些行业调研的方式、方法；同时我也需要跟客户持续沟通，所以对客户的心理、需求都比较了解，包括我也会做一些客户的调查工作，所以调查手段我也非常了解。同时我也配合市场部做一些线上线下的活动，因此我也对活动这一方面也有一定的经验。

> 刚刚也说了，我在活动策划、客户沟通、用户需求心理把握等方面是有一定的经验积累的，用户运营其实跟我之前的工作有很大的相关度。同时用户运营和销售岗相比，我认为这个岗位在未来更加有发展前景。所以我现在虽然是转行的过程，但是之前积累的经验和能力都可以直接利用起来、是有很大的迁移度的。

说完了为什么应聘岗位，还需要说为什么要选择这个公司以及行业。因为面试官不希望看到面试者在行业或者公司的选择上是随机、盲目的，而是希望每个面试者都是认真思考过公司和行业的选择，所以在面试之前就需要了解清楚公司的业务和行业的情况：

> 我之前是做房地产公司的销售，贵公司也是房地产行业的公司，所以我之前积累的一些对政策的理解、竞品公司的理解以及对市场环境的了解都是可以直接迁移过来的。同时，房地产互联网在我看来也是一个比较有发展的市场，所以我选择了这个行业。我在面试前对贵司的产品、业务、公众号等等都有一定的了解，贵司的价值观是XXXX，我也是非常认可的，客户对贵司的评价也是XXXX，所以我相信贵司是一个能够让员工发展、对客户负责的公司，同时这个岗位也能够让我充分地发挥自己的优势。所以我选择了贵司[用户运营](https://www.zhihu.com/search?q=用户运营&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A949376824})的岗位。



你好，我叫张海滨，2018年毕业于北京科技大学，到现在已经做了7年的java开发，先后做过一些单体项目以及微服务项目，最近2年也承担过产品和项目经理的职责，让我对软件开发流程有了更加深刻的理解。
离开上一家公司的原因有2个。
第一个是跟技术相关，我的上家公司也是我来北京后的第一家公司是一个外包公司，我们搞互联网的都心照不宣的是外包大多都是混子，这也是这两年我的感受，你技术上涉及不到核心的业务开发，对于我个人的竞争力而且总是换项目不够稳定，所以会产生一些职业焦虑。

对于后续的职业发展规划我希望是找一家拥有自己业务的甲方公司稳定下来，提升个人技术能力，自己也会在完成本职工作之余多钻研业务，让自己有更多的机会为公司做贡献，同时也让自己有更多的发展机会。

以上就是我的个人介绍，接下来讲一下我的项目内容。

## 二、项目简介

然后最近做的一个项目是一个新闻资讯类的项目，主要使用的技术是SpringBoot+MybatisPlus，用的关系型数据库是MySQL，非关系型数据库用的是redis和MongoDB，微服务框架用的是SpringCloud Alibaba,消息队列用的是Kafka，这个项目分为三个端，分别是APP端、自媒体端、管理员端。我自己参与了APP端和自媒体端的接口开发，在APP端做了用户登录功能和首页文章展示，自媒体端做了素材管理、文章的审核与发布以及文章上下架功能。

6个微服务：用户微服务，文章微服务，自媒体微服务，schedule微服务负责一些定时任务相关，app/wemedia网关微服务



## 三、开发过程讲解

### 1.APP端-登录功能

**【网关】**除了对接前后端还可以进行登录的鉴权，我在网关这里写了一个全局的过滤器，是实现了网关中GlobalGfilter接口的，过滤器有两个功能，如果判断你是登录请求，那我直接放行，如果不是登录请求就要判断token是否有效，使用token有三个好处：

**【token】**第一，避免了使用session导致的重复登录问题;第二解决了多服务共享数据的问题;第三可以节省大量的服务器内存。因为token，它可以存在浏览器的cookie中，不用存在服务器上。

这里token的认证方式采用JWT(Header、Payload、Signature)。

在拦截器中我还做了一个功能为后续的微服务提供用户信息：

拦截器和过滤器的区别：

①在前边提到的全局过滤器中，在放行之前，从token的payload载荷中取出用户id,设置到请求头。

②写一个token拦截器（implements HandlerInterceptor）(需要写WebMvcConfig实现WebMvcConfigurer接口)，在prehandle方法中取出用户id,然后存入ThreadLocal，因为ThreadLocal与本地线程绑定，而拦截器、controller、service、dao在同一线程中。（请求结束记得clear）

经过一层一层拦截过滤终于来到了controller，然后写主要逻辑。

登录首先要比对密码，这里可以讲一下加密算法。

**【加密算法】**加密算法可以分成可逆算法和不可逆算法，可逆算法是可以根据密文解析明文，不可密算法是不可以根据密文解析明文，然后可逆算法又分为对称加密算法和非对称加密算法。然后对称加密算法是加密与解密用的同一个密钥。非对称加密算法是公钥加密，私钥解密或者相反，然后我在做登录功能的时候，用到Bcrypt算法,然后它是不可逆算法，非常安全，然后在验证成功以后就会生成token，返回给前端。这是用户模式登陆，如果是游客模式的话，就会直接返回token。

### 5.自媒体端-文章审核

文章发布之后就是文章的审核了，本来说我们可以直接在文章发布逻辑的后面直接加上文章审核的部分，但是这里审核的整体我是用异步线程池来执行的，然后使用线程池主要是为了节省发布文章的流程，节省时间，快速响应给前端。

线程池有7个参数，分别是核心线程数、最大线程数、阻塞队列、拒绝策略（丢弃任务抛异常、或不抛异常）、多余的空闲线程存活时间、时间单位、线程工厂（用于创建线程，默认即可）。然后当时我们核心线程数是10、最大线程数是100、阻塞队列是500、非核心线程生存时间是10秒，拒绝策略是让调用者执行任务。

**【如何做】**不问就跳过

①在wemedia的config包里添加线程池类ThreadExecutorConfig（注解：@Configuration，@EnableAsync //开启异步调用）

②将审核的代码抽取到单独的类中处理，并且审核方法要返回值为void，这样异步才能生效，文章审核业务实现类的审核方法添加注解@Async("taskExecutor")，对应我们自定义线程池中的 @Bean("taskExecutor") ，表示使用我们自定义的线程池。

③在WmNewsServiceImpl将第五部分的调用方式改为调用WmNewsAuditService的审核方法

然后整整个审核用到了OCR技术的一种叫Tess4j，本地的文本审核用到了敏感词过滤算法DFA，然后还用到了阿里云的文本审核和图片审核功能，然后还用minio。业务逻辑是这样的，先把文本文章中的封面图片，还有文章图片从minio上面下载下来，然后做一个去重（Hashset），然后用 OCR识别技术把所有的图片里面的文本都识别出来，然后和文章的内容就一起进行一个本地的文本审核，如果通过了，然后再进行阿里云的文本审核和图片审核。

审核通过以后，根据当前时间判断是否**直接发布**，还是**未来发布**。

**【直接发布】**好，我先讲直接发布，直接发布就是说把文章的状态改成9（已发布），然后就调用 APP端的feign接口（feign模块写接口@FeignClient，article模块写一个类实现接口，相当于一个controller，然后在impl实现功能），然后创建或更新 APP端的文章。

然后app端的文章表id的生成方式我们采用雪花算法生成分布式id，取代了以往的主键自增策略，原因是随着业务增长文章表可能会占用很大的存储空间，将来可能要分库分表，id自增的话可能会产生重复id.

然后在创建APP端文章的时候，我遇到了一个很大的问题，就是说在查询首页文章的时候，数据库会查询自媒体的文章表，因为文章表的内容字段就是长文本，在高并发的时候出现了内存溢出的问题，然后我就这么解决的：我把文章表就分成了主表和内容表，然后在展示文章的时候就不查内容，就解决了这个问题。然后为了进一步提升查询文章的效率，我就把文章的那些内容就是长文本，用静态化模板引擎技术freemarker生成了一个静态网页，然后传到了minio之中，然后就把返回来的路径传到文章表之中。这个时候查询文章详细页就不用到数据库去查，就直接去minio上面查，就减轻了数据库的压力，这就是审核文章审核通过之后立即发布的逻辑。

### 6.自媒体端-文章延时精准发布

**【未来发布】**然后我们接着讲未来发布的逻辑，我把未来发布做成了一个定时任务，用到了spring task（默认单线程）, mysql 加redis的技术，用到了**分布式锁**（**数据库表的唯一索引，redis的setnx, zookeeper临时有序节点排序**），然后是为了在集群部署的时候防止定时任务的冲突。整个功能是由四个方法构成的：第一个是添加任务，第二个是同步刷新未来队列到当前队列。第三是从当前队列拉取任务，第四使用数据库同步到redis,而这一步是为了防止服务器宕机，做的数据的安全性的保存的操作。

首先**第一个方法添加任务**，添加任务就是把任务添加到数据库中，然后添加到redis缓存中，redis中我们采用两种数据类型做队列，我们用zset(sortedset)做未来任务队列，zset特点是有序不重复，与set的区别就是他有score作为依据来进行排序，这里我们用发布的时间戳当做score，用list做当前队列，左进右出，然后用定时任务不断刷新未来队列到当前队列。

在**第二个方法刷新未来队列到当前队列**时，我们需要进行key值匹配，这里没有使用keys模糊匹配，尽管功能强大但是会导致redis的CPU使用率很高，所以我们使用scan（基于游标的迭代器）命令，也是非常快。然后我们设置cron表达式为10s一次，**然后用分布式锁通过互斥来保持数据一致性，具体来说就是使用setnx（set if not exist）指令，**然后再用redis管道技术pipeline给优化了一下，这就是第二功能。

**第三功能**就是我从当前队列拉取任务执行，拉取任务就是说要把当前队列的任务删掉，删除任务表的记录， 然后更新任务的日志表的记录为已执行，然后在自媒体端调用定时任务拉取任务的时候设置成5s一次，并且加上分布式锁然后调用APP端的发表文章任务。

第四个功能就是说用数据库同步redis,是因为redis的持久化机制RDB（默认快照）在快照持久化期间可能会丢失数据，AOF（3种持久化方式，always,everysec,no）在宕机时会丢失一秒的数据，所以我们写一个同步数据到redis的方法，给该方法加上一个@postconstruct注解，这个注解会让该方法在系统启动时执行一次。好，这就是数据库同步redis的功能。



这里换成redisson

### 7.自媒体端-文章上下架

然后文章同步结束之后，还有一个文章上下架的功能，然后这里我采用了kafka传递消息，可以达到异步削峰解耦的功能，就为什么用kafka就没有RabbitMQ呢？虽然RabbitMQ也可以满足需求，就是说这是为了保证以后服务的访问量可能特别大，如果你现在用 RabbitMQ可能可以，但是如果到了高并发的时候，只有kafka才能实现这种高并发高可用，所以说这是为了以后来准备的。

## 四、柜员权限管理系统

### 1.定时服务跑批

银行业务中有一些轮岗调岗的跑批需求，开始的时候用开发接口的方式由行方调用来实现定时跑批，后来行方那边忘记给我们项目做申请了，就得另外实现，于是先用springTask来改造一下，这里的话存在一个问题就是在分布式环境中存在重复跑批的问题，所以就是用redis分布式锁在避免这种情况，后来开会，行方业务提出要看到跑批情况，所以我又改成xxl-job来实现定时服务。

### 2.异步线程池

**描述：**

tims系统修改人员信息中的姓名和手机号时，要将这两个信息同步到外关联系统。

**优化：**

1.使用异步调用可以避免阻塞主线程，使应用保持响应性。用户不会在修改界面等待同步外系统响应结果而产生不好的用户体验。

线程池可以减少创建和销毁线程的性能开销，能控制线程池中的并发数，否则会因为大量的线程争夺CPU资源造成阻塞。

2.tims岗位管理页面，岗位的调整信息需要邮件通知对应角色，邮件发送也改为了异步发送。不然页面响应时间过长。

### 3.拦截器

场景描述：

系统有7个角色，大致分为三类：普通角色，村行角色，总行角色。

行方业务要求根据这三类角色对查询权限进行控制，普通角色只能查自己，村行角色只能查本行，总行角色可以查全部，考虑到如果在所有接口都进行改造，所以希望提高一下效率，所以就把三类权限等级给角色赋上，然后使用拦截器对请求拦截，在拦截器中提前查出当前登录用户的权限等级，然后存储到ThreadLocal，供每个线程使用，ThreadLocal是线程隔离的，所以可以用这个类完成需求。

当然ThreadLocal有个小问题，存储在其中的数据不及时清理容易造成内存泄漏，所以在拦截器中重写afterCompletion方法，调用ThreadLocal.remove方法清除变量。



## 五、运营风险监测系统

我负责哪些模块？

有什么值得说的地方？

除了一些比较常规的业务逻辑以外，我做起来比较陌生和费事的可以说一下。

### 1.动态数据源配置

### 2.手动模型如何实现

那么首先就是在前端要有一个手动按钮，这个按钮的任务就是告诉后端我要运行哪个模型，可以理解为我把我想运行的东西加入了一个运行队列。那么实际上就是把相关的模型信息加入到特定的数据表里，初始化一个运行状态，运行了的就是1，未运行的就是0。

那么下面就是我们怎么把这个任务给调出来执行了。

首先我写一个线程运行监听器ThreadRunListener，实现了ServletContextListener接口，这个接口中有2个抽象方法，一个是servlet容器初始化ContextInitialized，一个是容器销毁contextDestroyed，在这个容器初始化方法里我们就开启一个线程。

这个线程是做什么的呢？

就是做循环每隔10s开启一个线程，那么这么多线程开启的话肯定就要用线程池了。

核心线程5，最大线程10，存活时间10s，阻塞队列20，拒绝策略 丢弃新任务。

那开启的这个线程做什么呢？就是从我们那个任务队列中取任务来执行了，每次就取1条任务来执行。

这里就存在一个分布式问题，就是生产环境部署3个节点，每个节点都要来抢占资源，但我们模型只能跑一次，所以要加分布式锁。

有这么几种实现方式，数据库，redis，zookeeper。

我们这里采用的redis。

如果我们采用原生redis的话，这里注意2个问题，就是加锁和删锁。

加锁的时候必须设置过期时间，而且必须是原子性操作，不然跟没设置过期时间一样，不设置过期时间就会造成死锁。

删锁的时候需要注意如果业务执行时间大于了过期时间就可能把别的线程的锁删了，怎么处理？可以把value设置成唯一值，比如uuid.

那这样的操作就类似于一个CAS操作了，就是读值，比较，更新。

但是这里还存在一个问题。

我们让时间变慢，当我伸手去redis拿值的时候，那个值比方说是1，它还在，等我拿到以后，它一下过期了，然后又进来一个新的线程锁，那我在内存比较时会返回一个true,但删的时候显然不是我要删的那个。

总结就是一句话，取值，对比，删除不是一个原子操作。

那怎么给弄成原子操作呢？我们可以使用redis的lua脚本。

那么还存在一个续期的问题的 话我们就需要估计一下业务执行时间然后给一个比较大的值就可以了。

那这样我们这个分布式锁就算完成了。RedLock:Distributed locks with Redis

需要说明的问题：

mc模块有3个节点。

### 3.对接易点进行统一登录认证

OAuth 2.0

授权码模式（authorization code）授权码是通过客户端的后台服务器，与"服务提供方"的认证服务器进行互动，设计了auth code，通过这个code再获取token的过程，是功能最完整、流程最严密的授权模式，也是使用最多的模式。

业务逻辑：

1.授权接口：ip:8080/idp/oauth2/authorize  GET

在访问应用系统主页时判断用户未登陆已登陆然后跳转登录页面或者主页这个动作，改为，在访问应用系统主页地址时，直接调用该接口，该接口会重定向到统一认证登录界面，输入用户名密码从而完成认证。

认证成功后会跳转到一个redirect_uri，这个参数是GET传过去的，我们把风险监测系统主页地址给传过去。

跳转的同时code和state(如果有的话)会跟在回调地址上作为参数，如redirect_uri?code=xxx&state=xxx

拿着这个code我们在应用接口中继续请求易点中**获取token的接口**。

2.获取token接口（getToken）:ip:8080/idp/oauth2/getToken

该接口正确返回一个access_token.

3.获取用户信息接口（getUserInfo）:ip:8080/idp/oauth2/getUserInfo

根据这个access_token作为参数继续发送请求，请求易点中**获取用户信息的接口**，然后拿到我们最终需要的用户信息，登录监测系统。

### 4.慢查询

①场景描述：

在人员岗位信息查询中，人员表有17000多条数据，岗位映射表中400多条数据，还有一张岗位表，业务要求查询的字段需要三表连接，连接后的数据有64w条，导致查询速度很慢，本地大约7s左右，生产大约5s左右。

**解决：**

1.先分页查询出人员编号，10条。

2.在第二次查询中，将人员表改为子查询，使用第一步的人员编号，将17000条变成10条，然后连接查询，效果显著，最终本地查询速度在150ms左右。

②人员身份信息采集中，进入页面的初始查询，查询时间在3s左右。**原因**：in的数据条数有2000多条

以下为《阿里巴巴java开发手册-嵩山版》要求：

【推荐】in操作能避免则避免，若实在避免不了，需要仔细评估in后边的集合元素数量，控制在1000个之内。

**一、t1.***

**二、添加索引**

使用explain查看索引已命中，但是但是耗时没有明显提升。

**三、IN改为LEFT JOIN**

原来逻辑：

单独查找出所有的机构号和用户号，然后用mybatis的foreach标签写进sql导致in后面有大量数据

修改：

将原来的单独的查询写进同一条sql，采用·子查询加左连接加索引的方法

改变逻辑以后查询速度变为150ms-1.3s

以上是dev环境，在sit环境中，大概是2s->200-300ms

**四、IN改为EXISTS**

因为不是子查询所以不能用exists,所以把原先的逻辑先改为子查询。

子查询使用 exists，会先进行主查询，将查询到的每行数据循环带入子查询校验是否存在，过滤出整体的返回数据；子查询使用 in，会先进行子查询获取结果集，然后主查询匹配子查询的结果集，返回数据。

外表内表相对大小情况不一样时，查询效率不一样：两表大小相当，in 和 exists 差别不大；内表大，用 exists 效率较高；内表小，用 in 效率较高。

耗时也没有明显提升。

**五、改用NoSQL**



## 六、其他个人项目

### 1. QQ机器人

```
###2022.10.10   
群内容审核，分为文字审核和图片审核，接入阿里云内容审核接口，群员发送违规信息的话，如果权限大于该群员则禁言加撤回消息，如果权限不够，则警告并@群主。  
###2022.10.11   
1.内容审核加入DFA敏感词过滤
2.图片审核加入tess4j OCR文字识别
###2022.10.18 v0.9.0
使用python实现色情图片鉴别，封装成webAPI,接入java,删除阿里云付费审核
```