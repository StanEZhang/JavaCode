# java面试逐字稿

## 一、自我介绍

面试官你好，我叫张海滨，2018年毕业于北京科技大学，到现在已经做了5年的java开发，先后做过一些单体项目以及微服务项目。

离开上一家公司的原因主要是想跳出自己的舒适圈，我的上家公司也是我来北京后的第一家公司是一个外包公司，我们也都知道在程序员的圈子里一直流传着35岁危机，在上家公司总感觉太安逸了，技术上涉及不到核心的业务开发，而且总是换项目不够稳定，所以会产生一些职业焦虑。对于后续的职业发展规划我希望是长久稳定的，对个人技术力有提升的，能够获得职业满足感的。

因此目前的意向是找一家拥有自己业务的甲方公司稳定下来，沉淀技术，同时学好外语，有利于自己的技术提升的同时，也是希望将来有更多的发展机会。

（面试外包）

离开上一家公司的原因主要是想跳出自己的舒适圈，换一个工作环境，学习一些新的项目技术，才能有更长足的发展。

以上就是我的个人介绍，接下来讲一下我的项目内容。

## 二、项目简介

然后最近做的一个项目是一个新闻资讯类的项目，主要使用的技术是SpringBoot+MybatisPlus，用的关系型数据库是MySQL，非关系型数据库用的是redis和MongoDB，微服务框架用的是SpringCloud Alibaba,消息队列用的是Kafka，这个项目分为三个端，分别是APP端、自媒体端、管理员端。我自己参与了APP端和自媒体端的接口开发，在APP端做了用户登录功能和首页文章展示，自媒体端做了素材管理、文章的审核与发布以及文章上下架功能。

6个微服务：用户微服务，文章微服务，自媒体微服务，schedule微服务负责一些定时任务相关，app/wemedia网关微服务



## 三、开发过程讲解

### 1.APP端-登录功能

下面我们从app端的登录开始讲起，首先前端点击登录按钮的话，就会发起一个地址请求，这个请求会被发送到Nginx上进行反向代理，根据Nginx的配置文件将请求送到网关微服务gateway，这里可以简单说一下**【微服务架构】**。



微服务架构的核心就是为了解决应用微服务化之后的服务治理问题。那什么叫应用微服务化呢？简单来说就是伴随技术发展，以前的单体服务架构已经满足不了各种互联网产品的要求了，你不可能指望像支付宝这样的应用一个人一台机器一个服务器就能跑起来，所以就慢慢出现了分布式服务架构（，解耦，不同模块部署到不同的服务器，业务与子业务，结合集群高可用），以及更加细粒度的微服务架构。

那一个微服务解决一个业务问题的话，相互之间有可能互相引用对吧，那就会出现一些问题：

**【服务发现问题】**我怎么找其他微服务？我可以把其他微服务地址配置到我自己这里。但万一有一百个微服务那不就要配置一万次，显然不行，要想办法解决。所以就有了**服务注册中心**，比如**eureka**,比如**nacos**,所有服务都注册上去，也可以从注册中心获取当前可以用的服务清单。服务之间的远程调用用OpenFeign实现，SpringCloud底层用Ribbon实现负载均衡。

**【服务配置问题】**还有就是配置问题，我每个配置都要分散到不同的微服务中去的话就会很难管理，所以就需要一个统一的**配置中心**进行管理，比如**nacos**或者s**pringcloudconfig.**

**【外部治理】**当客户端调用服务时候怎么处理的呢？服务A可能多个节点（ip），服务ABC地址又不同，授权验证怎么办？这时候需要一个网关提供统一的服务入口（统一地址），最终形成典型的微服务架构。



那微服务就说到这里，我们回到刚才，我们前端请求已经来到了gateway，gateway中的bootstrap.yml里面有注册中心和配置中心的地址，gateway从nacos拉取配置，根据其中的路由规则和路径匹配将请求路由到对应的微服务。

**【网关】**除了对接前后端还可以进行登录的鉴权，我在网关这里写了一个全局的过滤器，是实现了网关中GlobalGfilter接口的，过滤器有两个功能，如果判断你是登录请求，那我直接放行，如果不是登录请求就要判断token是否有效，使用token有三个好处：

**【token】**第一，避免了使用session导致的重复登录问题;第二解决了多服务共享数据的问题;第三可以节省大量的服务器内存。因为token，它可以存在浏览器的cookie中，不用存在服务器上。

这里token的认证方式采用JWT(Header、Payload、Signature)。

在拦截器中我还做了一个功能为后续的微服务提供用户信息：

拦截器和过滤器的区别：

①在前边提到的全局过滤器中，在放行之前，从token的payload载荷中取出用户id,设置到请求头。

②写一个token拦截器（implements HandlerInterceptor）(需要写WebMvcConfig实现WebMvcConfigurer接口)，在prehandle方法中取出用户id,然后存入ThreadLocal，因为ThreadLocal与本地线程绑定，而拦截器、controller、service、dao在同一线程中。（请求结束记得clear）

经过一层一层拦截过滤终于来到了controller，然后写主要逻辑。

登录首先要比对密码，这里可以讲一下加密算法。

**【加密算法】**加密算法可以分成可逆算法和不可逆算法，可逆算法是可以根据密文解析明文，不可密算法是不可以根据密文解析明文，然后可逆算法又分为对称加密算法和非对称加密算法。然后对称加密算法是加密与解密用的同一个密钥。非对称加密算法是公钥加密，私钥解密或者相反，然后我在做登录功能的时候，用到Bcrypt算法,然后它是不可逆算法，非常安全，然后在验证成功以后就会生成token，返回给前端。这是用户模式登陆，如果是游客模式的话，就会直接返回token。

### 5.自媒体端-文章审核

文章发布之后就是文章的审核了，本来说我们可以直接在文章发布逻辑的后面直接加上文章审核的部分，但是这里审核的整体我是用异步线程池来执行的，然后使用线程池主要是为了节省发布文章的流程，节省时间，快速响应给前端。

线程池有7个参数，分别是核心线程数、最大线程数、阻塞队列、拒绝策略（丢弃任务抛异常、或不抛异常）、多余的空闲线程存活时间、时间单位、线程工厂（用于创建线程，默认即可）。然后当时我们核心线程数是10、最大线程数是100、阻塞队列是500、非核心线程生存时间是10秒，拒绝策略是让调用者执行任务。

**【如何做】**不问就跳过

①在wemedia的config包里添加线程池类ThreadExecutorConfig（注解：@Configuration，@EnableAsync //开启异步调用）

②将审核的代码抽取到单独的类中处理，并且审核方法要返回值为void，这样异步才能生效，文章审核业务实现类的审核方法添加注解@Async("taskExecutor")，对应我们自定义线程池中的 @Bean("taskExecutor") ，表示使用我们自定义的线程池。

③在WmNewsServiceImpl将第五部分的调用方式改为调用WmNewsAuditService的审核方法

然后整整个审核用到了OCR技术的一种叫Tess4j，本地的文本审核用到了敏感词过滤算法DFA，然后还用到了阿里云的文本审核和图片审核功能，然后还用minio。业务逻辑是这样的，先把文本文章中的封面图片，还有文章图片从minio上面下载下来，然后做一个去重（Hashset），然后用 OCR识别技术把所有的图片里面的文本都识别出来，然后和文章的内容就一起进行一个本地的文本审核，如果通过了，然后再进行阿里云的文本审核和图片审核。

审核通过以后，根据当前时间判断是否**直接发布**，还是**未来发布**。

**【直接发布】**好，我先讲直接发布，直接发布就是说把文章的状态改成9（已发布），然后就调用 APP端的feign接口（feign模块写接口@FeignClient，article模块写一个类实现接口，相当于一个controller，然后在impl实现功能），然后创建或更新 APP端的文章。

然后app端的文章表id的生成方式我们采用雪花算法生成分布式id，取代了以往的主键自增策略，原因是随着业务增长文章表可能会占用很大的存储空间，将来可能要分库分表，id自增的话可能会产生重复id.

然后在创建APP端文章的时候，我遇到了一个很大的问题，就是说在查询首页文章的时候，数据库会查询自媒体的文章表，因为文章表的内容字段就是长文本，在高并发的时候出现了内存溢出的问题，然后我就这么解决的：我把文章表就分成了主表和内容表，然后在展示文章的时候就不查内容，就解决了这个问题。然后为了进一步提升查询文章的效率，我就把文章的那些内容就是长文本，用静态化模板引擎技术freemarker生成了一个静态网页，然后传到了minio之中，然后就把返回来的路径传到文章表之中。这个时候查询文章详细页就不用到数据库去查，就直接去minio上面查，就减轻了数据库的压力，这就是审核文章审核通过之后立即发布的逻辑。

### 6.自媒体端-文章延时精准发布

**【未来发布】**然后我们接着讲未来发布的逻辑，我把未来发布做成了一个定时任务，用到了spring task（默认单线程）, mysql 加redis的技术，用到了**分布式锁**（**数据库表的唯一索引，redis的setnx, zookeeper临时有序节点排序**），然后是为了在集群部署的时候防止定时任务的冲突。整个功能是由四个方法构成的：第一个是添加任务，第二个是同步刷新未来队列到当前队列。第三是从当前队列拉取任务，第四使用数据库同步到redis,而这一步是为了防止服务器宕机，做的数据的安全性的保存的操作。

首先**第一个方法添加任务**，添加任务就是把任务添加到数据库中，然后添加到redis缓存中，redis中我们采用两种数据类型做队列，我们用zset(sortedset)做未来任务队列，zset特点是有序不重复，与set的区别就是他有score作为依据来进行排序，这里我们用发布的时间戳当做score，用list做当前队列，左进右出，然后用定时任务不断刷新未来队列到当前队列。

在**第二个方法刷新未来队列到当前队列**时，我们需要进行key值匹配，这里没有使用keys模糊匹配，尽管功能强大但是会导致redis的CPU使用率很高，所以我们使用scan（基于游标的迭代器）命令，也是非常快。然后我们设置cron表达式为10s一次，**然后用分布式锁通过互斥来保持数据一致性，具体来说就是使用setnx（set if not exist）指令，**然后再用redis管道技术pipeline给优化了一下，这就是第二功能。

**第三功能**就是我从当前队列拉取任务执行，拉取任务就是说要把当前队列的任务删掉，删除任务表的记录， 然后更新任务的日志表的记录为已执行，然后在自媒体端调用定时任务拉取任务的时候设置成5s一次，并且加上分布式锁然后调用APP端的发表文章任务。

第四个功能就是说用数据库同步redis,是因为redis的持久化机制RDB（默认快照）在快照持久化期间可能会丢失数据，AOF（3种持久化方式，always,everysec,no）在宕机时会丢失一秒的数据，所以我们写一个同步数据到redis的方法，给该方法加上一个@postconstruct注解，这个注解会让该方法在系统启动时执行一次。好，这就是数据库同步redis的功能。



这里换成redisson

### 7.自媒体端-文章上下架

然后文章同步结束之后，还有一个文章上下架的功能，然后这里我采用了kafka传递消息，可以达到异步削峰解耦的功能，就为什么用kafka就没有RabbitMQ呢？虽然RabbitMQ也可以满足需求，就是说这是为了保证以后服务的访问量可能特别大，如果你现在用 RabbitMQ可能可以，但是如果到了高并发的时候，只有kafka才能实现这种高并发高可用，所以说这是为了以后来准备的。

## 四、柜员权限管理系统

### 1.定时服务跑批

银行业务中有一些轮岗调岗的跑批需求，开始的时候用开发接口的方式由行方调用来实现定时跑批，后来行方那边忘记给我们项目做申请了，就得另外实现，于是先用springTask来改造一下，这里的话存在一个问题就是在分布式环境中存在重复跑批的问题，所以就是用redis分布式锁在避免这种情况，后来开会，行方业务提出要看到跑批情况，所以我又改成xxl-job来实现定时服务。

### 2.异步线程池

**描述：**

tims系统修改人员信息中的姓名和手机号时，要将这两个信息同步到外关联系统。

**优化：**

1.使用异步调用可以避免阻塞主线程，使应用保持响应性。用户不会在修改界面等待同步外系统响应结果而产生不好的用户体验。

线程池可以减少创建和销毁线程的性能开销，能控制线程池中的并发数，否则会因为大量的线程争夺CPU资源造成阻塞。

2.tims岗位管理页面，岗位的调整信息需要邮件通知对应角色，邮件发送也改为了异步发送。不然页面响应时间过长。

### 3.拦截器

场景描述：

系统有7个角色，大致分为三类：普通角色，村行角色，总行角色。

行方业务要求根据这三类角色对查询权限进行控制，普通角色只能查自己，村行角色只能查本行，总行角色可以查全部，考虑到如果在所有接口都进行改造，所以希望提高一下效率，所以就把三类权限等级给角色赋上，然后使用拦截器对请求拦截，在拦截器中提前查出当前登录用户的权限等级，然后存储到ThreadLocal，供每个线程使用，ThreadLocal是线程隔离的，所以可以用这个类完成需求。

当然ThreadLocal有个小问题，存储在其中的数据不及时清理容易造成内存泄漏，所以在拦截器中重写afterCompletion方法，调用ThreadLocal.remove方法清除变量。

### 4.慢查询

①场景描述：

在人员岗位信息查询中，人员表有17000多条数据，岗位映射表中400多条数据，还有一张岗位表，业务要求查询的字段需要三表连接，连接后的数据有64w条，导致查询速度很慢，本地大约7s左右，生产大约5s左右。

**解决：**

1.先分页查询出人员编号，10条。

2.在第二次查询中，将人员表改为子查询，使用第一步的人员编号，将17000条变成10条，然后连接查询，效果显著，最终本地查询速度在150ms左右。

②人员身份信息采集中，进入页面的初始查询，查询时间在3s左右。**原因**：in的数据条数有2000多条

以下为《阿里巴巴java开发手册-嵩山版》要求：

【推荐】in操作能避免则避免，若实在避免不了，需要仔细评估in后边的集合元素数量，控制在1000个之内。

**一、t1.***

**二、添加索引**

使用explain查看索引已命中，但是但是耗时没有明显提升。

**三、IN改为LEFT JOIN**

原来逻辑：

单独查找出所有的机构号和用户号，然后用mybatis的foreach标签写进sql导致in后面有大量数据

修改：

将原来的单独的查询写进同一条sql，采用·子查询加左连接加索引的方法

改变逻辑以后查询速度变为150ms-1.3s

以上是dev环境，在sit环境中，大概是2s->200-300ms

**四、IN改为EXISTS**

因为不是子查询所以不能用exists,所以把原先的逻辑先改为子查询。

子查询使用 exists，会先进行主查询，将查询到的每行数据循环带入子查询校验是否存在，过滤出整体的返回数据；子查询使用 in，会先进行子查询获取结果集，然后主查询匹配子查询的结果集，返回数据。

外表内表相对大小情况不一样时，查询效率不一样：两表大小相当，in 和 exists 差别不大；内表大，用 exists 效率较高；内表小，用 in 效率较高。

耗时也没有明显提升。

**五、改用NoSQL**

## 五、运营风险监测系统

我负责哪些模块？

有什么值得说的地方？

除了一些比较常规的业务逻辑以外，我做起来比较陌生和费事的可以说一下。

### 1.动态数据源配置

### 2.手动模型如何实现

mc模块有3个节点。

## 六、其他个人项目

### 1. QQ机器人

```
###2022.10.10   
群内容审核，分为文字审核和图片审核，接入阿里云内容审核接口，群员发送违规信息的话，如果权限大于该群员则禁言加撤回消息，如果权限不够，则警告并@群主。  
###2022.10.11   
1.内容审核加入DFA敏感词过滤
2.图片审核加入tess4j OCR文字识别
###2022.10.18 v0.9.0
使用python实现色情图片鉴别，封装成webAPI,接入java,删除阿里云付费审核
```