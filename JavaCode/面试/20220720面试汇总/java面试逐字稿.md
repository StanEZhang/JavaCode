# java面试逐字稿

## 一、自我介绍

面试官你好，我叫张海滨，2018年毕业于北京科技大学，到现在已经做了4年的java开发，先后做过一些单体项目以及微服务项目。

离开上一家公司的原因主要是想跳出自己的舒适圈，我的上家公司也是我来北京后的第一家公司是一个外包公司，我们也都知道在程序员的圈子里一直流传着35岁危机，在上家公司总感觉太安逸了，技术上得不到特别大的提升，而且总是换项目不够稳定，所以总是产生一些职业焦虑。对于后续的职业发展规划我希望是长久稳定的，对个人技术力有提升的，能够获得职业满足感的。

个人平时的话除了一些必要的放松以外比如看看电影睡个懒觉，其余时间基本都投入到了四件事：编程、锻炼，学英语和阅读。

编程是本职工作，没事的时候就看看github有没有什么好项目，最近的打算是学习python和前端。

毛主席说过身体是革命的本钱，要让复利思想发挥到极致就需要有一个长久的职业生涯。

学英语是为了更好的与世界沟通，不论我们愿不愿意承认，世界最先进生产力依然是在西方世界，而西方世界的沟通语言就是英语，学好英语就等于少了一个发展屏障。

而阅读是开拓视野，提升认知和思想水平的有力手段。

而以上四件事都有一个核心指导，就是我前边提到过的复利思想，也就是所谓“合抱之木，生于毫末；九层之台，起于累土；千里之行，始于足下。”说的正是这个道理。

以上就是我的个人介绍，接下来讲一下我的项目内容。

## 二、项目简介

然后最近做的一个项目是一个新闻资讯类的项目，主要使用的技术是SpringBoot+MybatisPlus，用的关系型数据库是MySQL，非关系型数据库用的是redis和MongoDB，微服务框架用的是SpringCloud Alibaba,消息队列用的是Kafka，这个项目分为三个端，分别是APP端、自媒体端、管理员端。我自己参与了APP端和自媒体端的接口开发，在APP端做了用户登录功能和首页文章展示，自媒体端做了素材管理、文章的审核与发布以及文章上下架功能。

6个微服务：用户微服务，文章微服务，自媒体微服务，schedule微服务负责一些定时任务相关，app/wemedia网关微服务



## 三、开发过程讲解

### 1.APP端-登录功能

下面我们从app端的登录开始讲起，首先前端点击登录按钮的话，就会发起一个地址请求，这个请求会被发送到Nginx上进行反向代理，根据Nginx的配置文件将请求送到网关微服务gateway，这里可以简单说一下**【微服务架构】**。



微服务架构的核心就是为了解决应用微服务化之后的服务治理问题。那什么叫应用微服务化呢？简单来说就是伴随技术发展，以前的单体服务架构已经满足不了各种互联网产品的要求了，你不可能指望像支付宝这样的应用一个人一台机器一个服务器就能跑起来，所以就慢慢出现了分布式服务架构（，解耦，不同模块部署到不同的服务器，业务与子业务，结合集群高可用），以及更加细粒度的微服务架构。

那一个微服务解决一个业务问题的话，相互之间有可能互相引用对吧，那就会出现一些问题：

**【服务发现问题】**我怎么找其他微服务？我可以把其他微服务地址配置到我自己这里。但万一有一百个微服务那不就要配置一万次，显然不行，要想办法解决。所以就有了**服务注册中心**，比如**eureka**,比如**nacos**,所有服务都注册上去，也可以从注册中心获取当前可以用的服务清单。服务之间的远程调用用OpenFeign实现，SpringCloud底层用Ribbon实现负载均衡。

**【服务配置问题】**还有就是配置问题，我每个配置都要分散到不同的微服务中去的话就会很难管理，所以就需要一个统一的**配置中心**进行管理，比如**nacos**或者s**pringcloudconfig.**

**【外部治理】**当客户端调用服务时候怎么处理的呢？服务A可能多个节点（ip），服务ABC地址又不同，授权验证怎么办？这时候需要一个网关提供统一的服务入口（统一地址），最终形成典型的微服务架构。



那微服务就说到这里，我们回到刚才，我们前端请求已经来到了gateway，gateway中的bootstrap.yml里面有注册中心和配置中心的地址，gateway从nacos拉取配置，根据其中的路由规则和路径匹配将请求路由到对应的微服务。

**【网关】**除了对接前后端还可以进行登录的鉴权，我在网关这里写了一个全局的过滤器，是实现了网关中GlobalGfilter接口的，过滤器有两个功能，如果判断你是登录请求，那我直接放行，如果不是登录请求就要判断token是否有效，使用token有三个好处：

**【token】**第一，避免了使用session导致的重复登录问题;第二解决了多服务共享数据的问题;第三可以节省大量的服务器内存。因为token，它可以存在浏览器的cookie中，不用存在服务器上。

这里token的认证方式采用JWT(Header、Payload、Signature)。

在拦截器中我还做了一个功能为后续的微服务提供用户信息：

拦截器和过滤器的区别：

①在前边提到的全局过滤器中，在放行之前，从token的payload载荷中取出用户id,设置到请求头。

②写一个token拦截器（implements HandlerInterceptor）(需要写WebMvcConfig实现WebMvcConfigurer接口)，在prehandle方法中取出用户id,然后存入ThreadLocal，因为ThreadLocal与本地线程绑定，而拦截器、controller、service、dao在同一线程中。（请求结束记得clear）

<img src="java面试逐字稿/image-20221124221744314.png" alt="image-20221124221744314" style="zoom:50%;" /> 

经过一层一层拦截过滤终于来到了controller，然后写主要逻辑。

登录首先要比对密码，这里可以讲一下加密算法。

**【加密算法】**加密算法可以分成可逆算法和不可逆算法，可逆算法是可以根据密文解析明文，不可密算法是不可以根据密文解析明文，然后可逆算法又分为对称加密算法和非对称加密算法。然后对称加密算法是加密与解密用的同一个密钥。非对称加密算法是公钥加密，私钥解密或者相反，然后我在做登录功能的时候，用到Bcrypt算法,然后它是不可逆算法，非常安全，然后在验证成功以后就会生成token，返回给前端。这是用户模式登陆，如果是游客模式的话，就会直接返回token。

### 2.APP端-首页展示-列表上拉下拉

当我们验证密码正确后就会进入到app首页，首页会展示给我们一些推荐文章。登陆成功后前端发出一个请求，跟前边登录流程一样，经过Nginx反向代理转到app网关，不一样的是这次请求时token已经下发并携带着了，所以经过网关的全局过滤器就可以被放行，来到controller。

这里后端实际上是有三个接口的，分别是首页初始页面为load，上拉页面进入loadnew，下拉页面为loadmore，在controller中在通过分别传入不同参数控制后面的不同的sql查询。我们最终通过在xml中编写动态sql来最终决定是loadmore还是loadnew。

### 3.自媒体端-素材管理

然后我还做了一个素材管理的功能，用minio（分布式存储系统）来管理图片。自媒体用户可以上传素材、收藏、删除、查看等等一系列功能。然后当时技术选型的时候，参考阿里云OSS、七牛云，腾讯云，FastDFS，还有minio。阿里云、七牛云本身自身开发成本低也很好用，但是收费有点小贵，然后 FastDFS 可以搭集群，也可以动态扩容，但是安装部署比较麻烦，最近几年也没有更新，之后我选择了minIO，可以搭集群，使用也方便，提供了几乎所有主流开发语言的SDK及文档，而且还免费，但是需要自己在服务器上自己安装这个服务，自己维护。这里**素材的存储就需要与当前登录用户相关联**（ThreadLocal里的id），我们前边说的拦截器在这里就有用，然后整个功能比较简单，然后我就不讲了。

### 4.自媒体端-文章发布

然后自媒体的文章发布功能，发布文章那边可以填写文本和图片，这是自媒体用户自己填写，然后可以选择2种保存方式，一种是保存草稿，一种是提交审核，直接发布那里还可以选择发布的时间是当前时间还是未来时间，后面在审核的时候会用到这个时间。

新文章第一次保存草稿，怎么确保第一次？我们看一下文章id是否存在，如果为空，表示要创建文章数据，就直接保存就可以。

那如果查询不为空，说明以前保存过一次的文章，也就是这个请求时从草稿箱里过来的，这里就需要删除原来的一些关联关系，然后再更新。后面就是再把新的图片和文章关联关系建立起来。

提交审核跟刚刚保存草稿差不多，也是两种情况。

### 5.自媒体端-文章审核

文章发布之后就是文章的审核了，本来说我们可以直接在文章发布逻辑的后面直接加上文章审核的部分，但是这里审核的整体我是用异步线程池来执行的，然后使用线程池主要是为了节省发布文章的流程，节省时间，快速响应给前端。

线程池有7个参数，分别是核心线程数、最大线程数、阻塞队列、拒绝策略（丢弃任务抛异常、或不抛异常）、多余的空闲线程存活时间、时间单位、线程工厂（用于创建线程，默认即可）。然后当时我们核心线程数是10、最大线程数是100、阻塞队列是500、非核心线程生存时间是10秒，拒绝策略是让调用者执行任务。

**【如何做】***不问就跳过

①在wemedia的config包里添加线程池类ThreadExecutorConfig（注解：@Configuration，@EnableAsync //开启异步调用）

②将审核的代码抽取到单独的类中处理，并且审核方法要返回值为void，这样异步才能生效，文章审核业务实现类的审核方法添加注解@Async("taskExecutor")，对应我们自定义线程池中的 @Bean("taskExecutor") ，表示使用我们自定义的线程池。

③在WmNewsServiceImpl将第五部分的调用方式改为调用WmNewsAuditService的审核方法

然后整整个审核用到了OCR技术的一种叫Tess4j，本地的文本审核用到了敏感词过滤算法DFA，然后还用到了阿里云的文本审核和图片审核功能，然后还用minio。业务逻辑是这样的，先把文本文章中的封面图片，还有文章图片从minio上面下载下来，然后做一个去重（Hashset），然后用 OCR识别技术把所有的图片里面的文本都识别出来，然后和文章的内容就一起进行一个本地的文本审核，如果通过了，然后再进行阿里云的文本审核和图片审核。

审核通过以后，根据当前时间判断是否**直接发布**，还是**未来发布**。

**【直接发布】**好，我先讲直接发布，直接发布就是说把文章的状态改成9（已发布），然后就调用 APP端的feign接口（feign模块写接口@FeignClient，article模块写一个类实现接口，相当于一个controller，然后在impl实现功能），然后创建或更新 APP端的文章。

然后app端的文章表id的生成方式我们采用雪花算法生成分布式id，取代了以往的主键自增策略，原因是随着业务增长文章表可能会占用很大的存储空间，将来可能要分库分表，id自增的话可能会产生重复id.

然后在创建APP端文章的时候，我遇到了一个很大的问题，就是说在查询首页文章的时候，数据库会查询自媒体的文章表，因为文章表的内容字段就是长文本，在高并发的时候出现了内存溢出的问题，然后我就这么解决的：我把文章表就分成了主表和内容表，然后在展示文章的时候就不查内容，就解决了这个问题。然后为了进一步提升查询文章的效率，我就把文章的那些内容就是长文本，用静态化模板引擎技术freemarker生成了一个静态网页，然后传到了minio之中，然后就把返回来的路径传到文章表之中。这个时候查询文章详细页就不用到数据库去查，就直接去minio上面查，就减轻了数据库的压力，这就是审核文章审核通过之后立即发布的逻辑。

### 6.自媒体端-文章延时精准发布

**【未来发布】**然后我们接着讲未来发布的逻辑，我把未来发布做成了一个定时任务，用到了spring task（默认单线程）, mysql 加redis的技术，用到了**分布式锁**（**数据库表的唯一索引，redis的setnx, zookeeper临时有序节点排序**），然后是为了在集群部署的时候防止定时任务的冲突。整个功能是由四个方法构成的：第一个是添加任务，第二个是同步刷新未来队列到当前队列。第三是从当前队列拉取任务，第四使用数据库同步到redis,而这一步是为了防止服务器宕机，做的数据的安全性的保存的操作。

首先**第一个方法添加任务**，添加任务就是把任务添加到数据库中，然后添加到redis缓存中，redis中我们采用两种数据类型做队列，我们用zset(sortedset)做未来任务队列，zset特点是有序不重复，与set的区别就是他有score作为依据来进行排序，这里我们用发布的时间戳当做score，用list做当前队列，左进右出，然后用定时任务不断刷新未来队列到当前队列。

在**第二个方法刷新未来队列到当前队列**时，我们需要进行key值匹配，这里没有使用keys模糊匹配，尽管功能强大但是会导致redis的CPU使用率很高，所以我们使用scan（基于游标的迭代器）命令，也是非常快。然后我们设置cron表达式为10s一次，**然后用分布式锁通过互斥来保持数据一致性，具体来说就是使用setnx（set if not exist）指令，**然后再用redis管道技术pipeline给优化了一下，这就是第二功能。

**第三功能**就是我从当前队列拉取任务执行，拉取任务就是说要把当前队列的任务删掉，删除任务表的记录， 然后更新任务的日志表的记录为已执行，然后在自媒体端调用定时任务拉取任务的时候设置成5s一次，并且加上分布式锁然后调用APP端的发表文章任务。

第四个功能就是说用数据库同步redis,是因为redis的持久化机制RDB（默认快照）在快照持久化期间可能会丢失数据，AOF（3种持久化方式，always,everysec,no）在宕机时会丢失一秒的数据，所以我们写一个同步数据到redis的方法，给该方法加上一个@postconstruct注解，这个注解会让该方法在系统启动时执行一次。好，这就是数据库同步redis的功能。

### 7.自媒体端-文章上下架

然后文章同步结束之后，还有一个文章上下架的功能，然后这里我采用了kafka传递消息，可以达到异步削峰解耦的功能，就为什么用kafka就没有RabbitMQ呢？虽然RabbitMQ也可以满足需求，就是说这是为了保证以后服务的访问量可能特别大，如果你现在用 RabbitMQ可能可以，但是如果到了高并发的时候，只有kafka才能实现这种高并发高可用，所以说这是为了以后来准备的。

# 【消息丢失】

但是我当时还遇到一个问题就是说，由于生产者网络抖动，就没有把消息发送到kafka服务器，我是这么解决的，就说定义一个本地的消息日志表，然后在消息发送之前就把它存进去，在消息发送成功之后，再把消息表中的消息删除，然后就把这功能做成定时任务定时扫描，这个表就自动补偿就可以解决kafka消息发送失败。

好，大概就是这样。

# 【kafka架构】

producer:消息生产者

consumer：消息消费者

topic：主题-消息的分类-可以理解为一个队列

broker：一台kafka服务器就是一个broker，一个cluster由多个broker组成。

offset:偏移量

# 【消息有序性】

卡夫卡是无法保证全局的消息顺序性的。kafka中的每个partition中的消息在写入时都是有序的，而且单独一个partition只能由一个消费者去消费，可以在里面保证消息的有序性。但这样破坏了kafka的设计初衷。

# 【重复消费】

1、提高消费能力，提高单条消息的处理速度，例如对消息处理中比 较耗时的步骤可通过异步的方式进行处理、利用多线程处理等。

2、将消费的接口幂等处理，从而不用考虑重复消费的问题

①基于mysql唯一索引alter table 表名 add unique （“列”）

1.建立一张去重表，其中某个字段需要建立唯一索引
2.客户端去请求服务端，服务端会将这次请求的一些信息插入这张去重表中
3.因为表中某个字段带有唯一索引，如果插入成功，证明表中没有这次请求的信息，则执行后续的业务逻辑
4.如果插入失败，则代表已经执行过当前请求，直接返回

②基于 SETNX 命令实现的 SETNX key value

1.客户端先请求服务端，会拿到一个能代表这次请求业务的唯一字段
2.将该字段以 SETNX 的方式存入 redis 中，并根据业务设置相应的超时时间
3.如果设置成功，证明这是第一次请求，则执行后续的业务逻辑
4.如果设置失败，则代表已经执行过当前请求，直接返回

## 【削峰】

消息积压处理：

1、发送端优化，增加批量和线程并发两种方式处理

2、消费端优化，优化业务逻辑代码、水平扩容增加并发并同步扩容分区数量。或者建立临时队列，将已经积压的大量数据导入多个临时队列，然后增加服务器数量去处理。

# 项目二

这个项目我主要负责的是企业信息管理，企业管理员更新，考勤后台管理，移动端打卡。

首先是这个**企业基本信息的查询**，我们根据当前管理员登录是选择的企业ID，查询企业基本信息用于页面回显，这个企业ID，我们只需要在服务端通过ThreadLocal获取用户信息，这个ThreadLocal是一个与当前线程绑定的这么一个变量，他的内部维护了一个ThreadLocalMap，它是与其他线程隔离的不能互相访问，我们在网关微服务里写一个全局过滤器，在过滤器中把ID存到请求头上，之后在token拦截器中取出这个ID存到ThreadLocal中，业务层便可以通过ThreadLocal取出用户信息。使用阿里云OSS技术保存企业logo。

**更新企业管理员**时，先进行登录验证，然后获取当前登录用户的企业ID companyId；根据companyId查询查询主管理员。使用阿里云短信服务工具类发送短信验证码，同时将短信验证码存入redis中，设置过期时间，以备短信校验，校验码验证成功则删除存入redis的验证码；查看管理员列表选择员工，在进行短信验证，验证成功之后保存设置。

然后是**考勤组列表接口**，首先我们查询当前企业是否初次使用，如果是初次使用需要新增默认考勤组，设置企业所有部门员工都采用默认考勤组，这样的话不管你是不是第一次查询我们都能查到企业的考勤组列表数据，然后获取企业考勤组中参与者的数量，组装结果返回。

还有一个**移动端打卡**，首先我们要获取考勤组，怎么获取呢，我们根据用户ID查询考勤关联数据，如果查不到就获取他的上级部门ID，根据部门ID和类型获取考勤数据，回显到前端。

打卡的话就是先组装一下打卡信息，然后判断考勤组是否存在，存在的话判断是不是工作日，然后判断是不是有效打卡，然后保存打卡信息。